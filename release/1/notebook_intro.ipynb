{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook and NumPy introduction\n",
    "\n",
    "Jupyter notebook is often used by data scientists who work in Python. It is loosely based on Mathematica and combines code, text and visual output in one page.\n",
    "\n",
    "## Basic Jupyter Notebook commands\n",
    "\n",
    "Some relevant short cuts:\n",
    "* ```SHIFT + ENTER``` executes 1 block of code called a cell\n",
    "* Tab-completion is omnipresent after the import of a package has been executed\n",
    "* ```SHIFT + TAB``` gives you extra information on what parameters a function takes\n",
    "* Repeating ```SHIFT + TAB``` multiple times gives you even more information\n",
    "\n",
    "To get used to these short cuts try them out on the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hello world!')\n",
    "print(list(range(5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "In Python you need to import tools to be able to use them. In this workshop we will mainly use the numpy toolbox and you can import it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parts to be implemented\n",
    "\n",
    "In cells like the following example you are expected to implement some code. The remainder of the tutorial won't work if you skip these.\n",
    "\n",
    "Sometimes assertions are added as a check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1e931b4438c639e34ae723e72c1bf77",
     "grade": false,
     "grade_id": "example_impl",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# To proceed, implement the missing code, and remove the 'raise NotImplementedException()'\n",
    "\n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# three = ?\n",
    "assert three == 3\n",
    "\n",
    "print('Good job!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy arrays\n",
    "\n",
    "We'll be often working with numpy arrays so here's a short introduction. \n",
    "[`np.array()`](https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.array.html) create a new array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# This is a two-dimensional numpy array:\n",
    "arr = np.array([[1,2,3,4],[5,6,7,8]])\n",
    "print(arr, '\\n')\n",
    "\n",
    "# The shape is a tuple describing the size of each dimension\n",
    "print(f\"shape={arr.shape}\")\n",
    "\n",
    "# Elements are selected by specifying two indices, counting from 0\n",
    "print(f\"arr[1][3] = {arr[1][3]}\", '\\n')\n",
    "\n",
    "# This is a three-dimensional numpy array\n",
    "arr3 = np.array([[[1, 2, 3, 4], [5, 6, 7, 8]], [[9, 10, 11, 12], [13, 14, 15, 16]]])\n",
    "print(arr3, '\\n')\n",
    "\n",
    "print(f\"shape={arr3.shape}\")\n",
    "\n",
    "# Elements in a three dimensional array are selected by specifying three indices, counting from 0\n",
    "print(f\"arr3[1][0][2] = {arr3[1][0][2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we used `print(f\"foo {bar}\")` to enter a variable `bar` into the print statement using curly brackets? This syntax is called 'f-strings' (notice the `f` before the first quote), extra documentation can be found [here](https://www.datacamp.com/community/tutorials/f-string-formatting-in-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The numpy reshape method allows one to change the shape of an array, while keeping the underlying data.\n",
    "# One can leave one dimension unspecified by passing -1, it will be determined from the size of the data.\n",
    "\n",
    "print(\"Original array:\")\n",
    "print(arr, '\\n')\n",
    "\n",
    "print(\"As 4x2 matrix\")\n",
    "print(np.reshape(arr, (4,2)), '\\n')\n",
    "\n",
    "print(\"As 8x1 matrix\")\n",
    "print(np.reshape(arr, (-1,1)), '\\n')\n",
    "\n",
    "print(\"As 2x2x2 array\")\n",
    "print(np.reshape(arr, (2,2,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the numpy sum, mean min and max can be used to calculate aggregates across any axis\n",
    "table = np.array([[10.9, 12.1, 15.2, 7.3], [3.9, 1.2, 34.6, 8.3], [1.9, 23.3, 1.2, 3.7]])\n",
    "print(table)\n",
    "\n",
    "# Calculating the maximum across the first axis (=0).\n",
    "max0 = np.max(table, axis=0)\n",
    "# Calculating the maximum across the second axis (=1).\n",
    "max1 = np.max(table, axis=1)\n",
    "# Calculating the overall maximum.\n",
    "max_overall = np.max(table)\n",
    "\n",
    "print(f\"Maximum over the rows of the table = {max0}\")\n",
    "print(f\"Maximum over the columns of the table = {max1}\")\n",
    "print(f\"Overall maximum of the table = {max_overall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic arithmetical operations on arrays of the same shape are done elementwise: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1.,2.,3.])\n",
    "y = np.array([4.,5.,6.])\n",
    "\n",
    "print(x + y)\n",
    "print(x - y)\n",
    "print(x * y)\n",
    "print(x / y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use matplotlib.pyplot to make various types of plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A basic plot a list of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([7.3, 8.2, 1.2, 3.2, 9.1, 1.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting a list of X and Y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([100.0, 110.0, 120.0, 130.0, 140.0, 150.0],[2.3, 8.1, 9.3, 9.7, 9.8, 20.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using mathematical functions and plotting more than one line on a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 10, 0.1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most numpy function work on arrays as well by applying the function to each element in turn\n",
    "y_cos = np.cos(x)\n",
    "y_sin = np.sin(x)\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.plot(x, y_cos, x, y_sin)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data import and inspection (optional)\n",
    "\n",
    "[Pandas](http://pandas.pydata.org/) is a popular library for data wrangling, we'll use it to load and inspect a csv file that contains the historical web request and cpu usage of a web server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/request_rate_vs_CPU.csv\")\n",
    "print(f'The dataframe has {data.shape[0]} rows and {data.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The head command allows one to quickly inspect the first rows of the loaded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select the CPU column and plot the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot(figsize=(13, 6), y=\"CPU\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that to show the plot, we need to import `matplotlib.pyplot` and execute the `show()` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot the request rates, leaving out the CPU column  as it has another unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns='CPU').plot(figsize=(13, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to continue and start on modelling the data, we'll work with basic numpy arrays. By doing this we also drop the time-information as shown in the plots above.\n",
    "\n",
    "We extract the column labels as the request_names for later reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_names = data.drop(columns='CPU').columns.values\n",
    "request_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the request rates as a 2-dimensional numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_rates = data.drop(columns='CPU').values\n",
    "print(request_rates.shape)\n",
    "request_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the cpu usage as a one-dimensional numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = data['CPU'].values\n",
    "cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will dive deeper into Pandas in the Data and Feature Engineering section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
