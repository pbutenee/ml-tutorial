{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 101++ in Python\n",
    "\n",
    "#### Created by:\n",
    "\n",
    "- Pieter Buteneers ([@PieterButeneers](https://twitter.com/pieterbuteneers)), Director of Engineering in ML & AI at [sinch.com](https://www.sinch.com/) \n",
    "- Bart De Vylder, Senior Research Engineer at [Google DeepMind](https://deepmind.com/)\n",
    "- Jeroen Boeye ([@JeroenBoeye](https://twitter.com/JeroenBoeye)), Senior Machine Learning Engineer at [Faktion](https://www.faktion.com/)\n",
    "- Joris Boeye ([@JorisBoeye](https://twitter.com/JorisBoeye)), Senior Data Scientist at [ZF Wind Power](https://www.zf.com/products/en/wind/home/wind.html)\n",
    "\n",
    "\n",
    "\n",
    "## 1. Imports\n",
    "\n",
    "Let's first start with importing all the necessary packages. Some imports will be repeated in the exercises but if you want to skip some parts you can just execute the imports below and start with any exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (13.0, 8.0)\n",
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "\n",
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import sklearn.gaussian_process\n",
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Regression\n",
    "\n",
    "Linear Regression assumes a linear relationship between 2 variables. \n",
    "\n",
    "As an example we'll consider the historical page views of a web server and compare it to its CPU usage. We'll try to predict the CPU usage of the server based on the page views of the different pages. \n",
    "\n",
    "### 2.1 Data import and inspection\n",
    "\n",
    "Let's import the data and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle # Pickle files allow us to easily save and load python objects.\n",
    "\n",
    "with open('data/cpu_page_views.pickle', 'rb') as file:\n",
    "    cpu_usage, page_views, page_names, total_page_views = pickle.load(file, encoding='latin1')\n",
    "\n",
    "print('Array shapes:')\n",
    "print('-'*25)\n",
    "print(f'cpu_usage\\t {cpu_usage.shape}')\n",
    "print(f'page_views\\t {page_views.shape}')\n",
    "print(f'page_names\\t {page_names.shape}')\n",
    "print(f'total_page_views {total_page_views.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "plt.plot(total_page_views, label='Total page views')\n",
    "plt.plot(cpu_usage, label='CPU %')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The orange line on the plot above is the number of page views in blue and the orange line is the CPU load that viewing this pages generates on the server.\n",
    "\n",
    "### 2.2 Simple linear regression\n",
    "\n",
    "First, we're going to work with the total page views on the server, and compare it to the CPU usage. We can make use of a [PyPlot's scatter plot](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter) to understand the relation between the total page views and the CPU usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39d638331c51df5f39d212dfe8ba027d",
     "grade": false,
     "grade_id": "scatter",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "plt.xlabel(\"Total page views\")\n",
    "plt.ylabel(\"CPU usage\")\n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# plt.scatter( ? , ? )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There clearly is a strong correlation between the page views and the CPU usage. Because of this correlation we can build a model to predict the CPU usage from the total page views. If we use a linear model we get a formula like the following:\n",
    "\n",
    "$$ \\text{cpu_usage} = c_0 + c_1 \\text{total_page_views} $$\n",
    "\n",
    "Since we don't know the exact values for $c_0$ and $c_1$ we will have to compute them. For that we'll make use of the [scikit-learn](http://scikit-learn.org/stable/) machine learning library for Python and use [least-squares linear regression](http://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "simple_lin_model = sklearn.linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to feed the data to the model to fit it.\n",
    "```\n",
    "      X = [[x_11, x_12, x_13, ...],                  y = [y_1,\n",
    "           [x_21, x_22, x_23, ...],                       y_2,  \n",
    "           [x_31, x_32, x_33, ...],                       y_3,\n",
    "           ...]                                           ...]\n",
    "\n",
    "```\n",
    "\n",
    "In general, the [model.fit(X,y)](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.fit) method takes a matrix X and vector y as arguments and tries to find coefficients that allow to predict the `y_i`'s from the `x_ij`'s. In our case the matrix X will consist of only one column containing the total page views. Our `total_page_views` variable however, is still only a one-dimensional vector, so we need to [`np.reshape()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html) it into a two-dimensional array. Since there is only one feature the second dimension should be `1`. You can leave one dimension unspecified by passing -1, it will be determined from the size of the data.\n",
    "\n",
    "Then we fit our model using the the total page views and cpu. The coefficients found are automatically stored in the ```simple_lin_model``` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c08a2f0ad70a94236a4ee1d99c162ff",
     "grade": false,
     "grade_id": "model_fit",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# simple_lin_model.fit( ? , ? ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now inspect the coefficient $c_1$ and constant term (intercept) $c_0$ of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Coefficient = {simple_lin_model.coef_[0]:.2f}\\nConstant term = {simple_lin_model.intercept_:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this means that each additional page view adds about 0.11% CPU load to the server and all the other processes running on the server consume on average 0.72% CPU.\n",
    "\n",
    "Once the model is trained we can use it to [```predict```](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.predict) the outcome for a given input (or array of inputs). Note that the predict function requires a 2-dimensional array similar to the ```fit``` function.\n",
    "\n",
    "What is the expected CPU usage when we have 880 page views per second?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "92d234073f5e5f61c371dfbbfae30040",
     "grade": false,
     "grade_id": "predict_100",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# simple_lin_model.predict( [[ ? ]] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the expected CPU usage when we have 1000 page views per second? Is this technically possible? Why does the model predict it this way?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8af89df41a3e92ef7258d66761f52012",
     "grade": false,
     "grade_id": "cell-b9ac995304287553",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# simple_lin_model.predict( [[ ? ]] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the linear model together with our data to verify it captures the relationship correctly (the predict method can accept the entire ```total_page_views``` array at once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "\n",
    "plt.scatter(total_page_views, cpu_usage,  color='black')\n",
    "plt.plot(total_page_views, simple_lin_model.predict(total_page_views.reshape((-1, 1))), color='blue', linewidth=3)\n",
    "\n",
    "plt.xlabel(\"Total page views\")\n",
    "plt.ylabel(\"CPU usage\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model can calculate the R2 [`score`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score) indicating how well the linear model captures the data. A score of 1 means there is perfect linear correlation and the model can fit the data perfectly, a score of 0 (or lower) means that there is no correlation at all (and it does not make sense to try to model it that way). The score method takes the same arguments as the fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = simple_lin_model.score(total_page_views.reshape((-1, 1)), cpu_usage)\n",
    "print(f'R2 = {R2:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Extrapolation\n",
    "\n",
    "Now let's repeat this experiment with similar but different data. We will try to predict what the CPU usage will be if there will be 8 page views (per second)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/cpu_page_views_2.pickle', 'rb') as file:\n",
    "    cpu_usage, total_page_views = pickle.load(file, encoding='latin1')\n",
    "\n",
    "print('Array shapes:')\n",
    "print('-'*25)\n",
    "print(f'cpu_usage\\t {cpu_usage.shape}')\n",
    "print(f'total_page_views {total_page_views.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "42c17b94601aecd1aa9198080ae01a77",
     "grade": false,
     "grade_id": "qwerqwer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "simple_lin_model = sklearn.linear_model.LinearRegression()\n",
    "simple_lin_model.fit(total_page_views, cpu_usage)\n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# prediction = simple_lin_model.predict(?)\n",
    "\n",
    "print(f'The predicted value is: {prediction}')\n",
    "\n",
    "assert prediction < 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot what you have done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_page_views = np.concatenate((total_page_views, [[8]]))\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "\n",
    "plt.scatter(total_page_views, cpu_usage,  color='black')\n",
    "plt.plot(all_page_views, simple_lin_model.predict(all_page_views), color='blue', linewidth=3)\n",
    "plt.axvline(8, color='r')\n",
    "\n",
    "plt.xlabel(\"Total page views\")\n",
    "plt.ylabel(\"CPU usage\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this what you would expect? Can you see what's wrong?\n",
    "\n",
    "Let's plot the time series again to get a different view at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.plot(total_page_views, label='Total page views')\n",
    "plt.plot(cpu_usage, label='CPU %')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "selection = np.array([True, False, True])\n",
    "x[selection]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spikes of CPU usage are actually backups that run at night and they can be ignored. So repeat the exercise again but ignore these data points.\n",
    "\n",
    "You can subselect parts of arrays with a second array that holds True / False values like so:\n",
    "```\n",
    "    x = np.array([1, 2, 3])\n",
    "    selection = np.array([True, False, True])\n",
    "    print(x[selection])\n",
    "    array([1, 3])\n",
    "```\n",
    "\n",
    "Try to create this `selection` array with `True` values where there is no backup going on and `False` when the backup occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7de0328f7131b3f8b628dd11d458c1e4",
     "grade": false,
     "grade_id": "qwerqwe",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# selection = ?\n",
    "\n",
    "assert selection.dtype == np.dtype('bool'), 'The selection variable should be an array of True/False values'\n",
    "assert len(selection) == len(total_page_views)\n",
    "\n",
    "simple_lin_model = sklearn.linear_model.LinearRegression()\n",
    "simple_lin_model.fit(total_page_views[selection], cpu_usage[selection])\n",
    "prediction = simple_lin_model.predict([[8]])\n",
    "\n",
    "print(f'The predicted value is: {prediction}')\n",
    "\n",
    "all_page_views = np.concatenate((total_page_views, [[8]]))\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "\n",
    "plt.scatter(total_page_views, cpu_usage,  c=selection, cmap='RdYlGn')\n",
    "plt.plot(all_page_views, simple_lin_model.predict(all_page_views), color='blue', linewidth=3)\n",
    "plt.axvline(8, color='r')\n",
    "\n",
    "plt.xlabel(\"Total page views\")\n",
    "plt.ylabel(\"CPU usage\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "assert prediction > 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what you should have learned from the previous exercise is that you should always look at your data and/or write scripts to inspect your data. Additionally extrapolation does not always work because there are no training examples in that area.\n",
    "\n",
    "## 3. Multiple linear regression\n",
    "\n",
    "A server can host different pages and each of the page views will generate load on the CPU. This load will however not be the same for each page.\n",
    "\n",
    "Now let us consider the separate page views and build a linear model for that. The model we try to fit takes the form:\n",
    "\n",
    "$$\\text{cpu_usage} = c_0 + c_1 \\text{page_views}_1 + c_2 \\text{page_views}_2 + \\ldots + c_n \\text{page_views}_n$$\n",
    "\n",
    "where the $\\text{page_views}_i$'s correspond the our different pages:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "with open('data/cpu_page_views.pickle', 'rb') as file:\n",
    "    cpu_usage, page_views, page_names, total_page_views = pickle.load(file, encoding='latin1')\n",
    "\n",
    "print('Array shapes:')\n",
    "print('-'*25)\n",
    "print(f'cpu_usage\\t {cpu_usage.shape}')\n",
    "print(f'page_views\\t {page_views.shape}')\n",
    "print(f'page_names\\t {page_names.shape}')\n",
    "print(f'total_page_views {total_page_views.shape}\\n')\n",
    "\n",
    "print(page_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "for i in range(len(page_names)):\n",
    "    plt.plot(page_views[:,i], label=page_names[i])\n",
    "plt.plot(cpu_usage, label= 'CPU %')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "\n",
    "for i in range(len(page_names)):\n",
    "    plt.scatter(page_views[:,i], cpu_usage,  label=page_names[i])\n",
    "\n",
    "plt.xlabel(\"Page views\")\n",
    "plt.ylabel(\"CPU usage\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start again by creating a [```LinearRegression```](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_lin_model = sklearn.linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit the model on the data, using `multi_lin_model.fit(X,y)`. In contrast to the case above our `page_views` variable already has the correct shape to pass as the X matrix: it has one column per page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e95bd2b512228ec440de2dbc8e7e3c8",
     "grade": false,
     "grade_id": "multi_lin_model_fit",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# multi_lin_model.fit( ? , ? )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, given the coefficients calculated by the model, which capture the contribution of each page view to the total CPU usage, we can start to answer some interesting questions. For example, \n",
    "which page view causes most CPU usage, on a per visit basis? \n",
    "\n",
    "For this we can generate a table of page names with their coefficients in descending order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some quick and dirty code to print the most consuming pages first\n",
    "print('Index\\tCPU (%)\\t Page')\n",
    "print('-'*41)\n",
    "\n",
    "indices = np.argsort(-multi_lin_model.coef_)\n",
    "for i in indices:\n",
    "    print(f\"{i}\\t{ multi_lin_model.coef_[i]:4.2f}\\t {page_names[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this table we see that 'resources/js/basket.js' consumes the most per CPU per view. It generates about 0.30% CPU load for each additional page view. 'products/science.html' on the other hand is much leaner and only consumes about 0.04% CPU per view. Does this seem to be correct if you look at the scatter plot above?\n",
    "\n",
    "Now let us investigate the constant term again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The other processes on the server consume {multi_lin_model.intercept_:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this term is very similar to the result achieved in single linear regression, but it is not entirely the same. This means that these models are not perfect. However, they seem to be able to give a reliable estimate.\n",
    "\n",
    "Now let's compute the R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = multi_lin_model.score(page_views, cpu_usage)\n",
    "print(f'R2 = {R2:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the R2 score, this model performs better. It can explain 91.5% of the variance instead of just 90.5% of the variance. So this gives the impression that this model is more accurate.\n",
    "\n",
    "## 4. Non-linear Regression\n",
    "\n",
    "Sometimes linear relations don't cut it anymore, so you might want a more complex method. There are 2 approaches to this:\n",
    "* Use a non-linear method (such as Neural Networks, Support Vector Machines, Random Forests and Gaussian Processes)\n",
    "* Use non-linear features as pre-processing for a linear method\n",
    "\n",
    "Actually both methods are in essence identical and there is not always a clear distinction between the two. We will use the second approach in this section since it is easier to understand what is going on.\n",
    "\n",
    "Please note that it is very often not even necessary to use non-linear methods, since the linear methods can be extremely powerful on their own and they are quite often very stable and reliable (in contrast to non-linear methods).\n",
    "\n",
    "### 4.1. Fitting a sine function with linear regression\n",
    "\n",
    "As an example task, we'll try to fit a sine function. We will use the [`np.sin()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.sin.html) function to compute the sine of the elements in a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,6, 0.01).reshape((-1, 1))\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.plot(x, np.sin(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our training set, we will calculate 10 _y_ values from evenly spaced _x_ values using this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to generate the data\n",
    "def sine_train_data(): \n",
    "    x_train = np.linspace(0, 6, 10).reshape((-1, 1))\n",
    "    y_train = np.sin(x_train)\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = sine_train_data()\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to fit a model to this data with linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0b990debec632693543df6593e36d85",
     "grade": false,
     "grade_id": "qwerq2",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train = sine_train_data()\n",
    "\n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# model = ?\n",
    "# model.fit( ? )\n",
    "\n",
    "print(f'The R2 score of this model is: {model.score(x_train, y_train):.3}')\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.scatter(x_train, y_train)\n",
    "plt.plot(x, model.predict(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this fit is not optimal.\n",
    "\n",
    "### 4.2. Fitting a sine function using polynomial expansion\n",
    "\n",
    "One of the easiest ways to make your machine learning technique more *intelligent* is to extract relevant features from the data. These features can be anything that you can find that will make it easier for the method to be able to fit the data. This means that as a machine learning engineer it is best to know and understand your data.\n",
    "\n",
    "As some of you might remember from math class, you can create an approximation of any function (including a sine function) using a polynomial function with the [Taylor expansion](https://en.wikipedia.org/wiki/Taylor_series). So we will use that approach to learn a better fit.\n",
    "\n",
    "In this case we will create what we call features using a [polynomial expansion](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html). If you set the degree to 3 it will generate data of the 0d, 1st, 2nd and 3rd order (including cross products) as shown in the example below (change `x` and `degree` to see the different expansions of `x` to a certain `degree`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "\n",
    "x = [[2]]\n",
    "pol_exp = sklearn.preprocessing.PolynomialFeatures(degree=3)\n",
    "pol_exp.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above this function transforms $x$ into [$x^0$, $x^1$, $x^2$, $x^3$] with $x^0=1$ and $x^1 = x$. If you have 2 inputs it will also take the cross products so that [$x_1$, $x_2$] is transformed into: [1, $x_1$, $x_2$, $x_1^2$, $x_1x_2$, $x_2^2$, $x_1^3$, $x_1^2x_2$, $x_1x_2^2$, $x_2^3$] as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [[2, 3]]\n",
    "pol_exp = sklearn.preprocessing.PolynomialFeatures(degree=3)\n",
    "pol_exp.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we only have 1 input so the number of features is always the `degree + 1`.\n",
    "\n",
    "Because of this polynomial features extraction finding of the coefficients of the polynomial becomes a linear problem, so similar to the previous exercise on multiple linear regression you can find the optimal weights as follows:\n",
    "\n",
    "$$y = c_0 + c_1 x + c_2 x^2 + c_3 x^3 + \\cdots + c_n x^n$$\n",
    "\n",
    "So for multiple values of $x$ and $y$ you can minimize the error of this equation using linear regression. How this is done in practice is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = sine_train_data()\n",
    "\n",
    "pol_exp = sklearn.preprocessing.PolynomialFeatures(degree=3)\n",
    "pol_exp.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now play with the degree of the polynomial expansion function below to create better features. Search for the optimal degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3752f06005eae427e3ea49f57a6aa5d9",
     "grade": false,
     "grade_id": "qwerq",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train = sine_train_data()\n",
    "\n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# pol_exp = sklearn.preprocessing.PolynomialFeatures(degree= ? )\n",
    "\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(pol_exp.fit_transform(x_train), y_train)\n",
    "\n",
    "train_score = model.score(pol_exp.fit_transform(x_train), y_train)\n",
    "print(f'The R2 score of this model is: {train_score:.6f}')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.scatter(x_train, y_train)\n",
    "x = np.arange(0,6, 0.01).reshape((-1, 1))\n",
    "plt.plot(x, model.predict(pol_exp.fit_transform(x)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice? When does it work better? And when does it work best?\n",
    "\n",
    "Now let's test this on new and unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sine_test_data():\n",
    "    x_test = 0.5 + np.arange(6).reshape((-1, 1))\n",
    "    y_test = np.sin(x_test)\n",
    "    return x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "147ec8d6cfdba0d03780cc03f753232b",
     "grade": false,
     "grade_id": "qwer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "assert train_score > .99999, 'Adjust the degree parameter 2 cells above until the train_score > .99999'\n",
    "\n",
    "x_test, y_test = sine_test_data()\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.scatter(x_train, y_train, label='train')\n",
    "plt.scatter(x_test, y_test, color='r', label='test')\n",
    "plt.legend()\n",
    "x = np.arange(0, 6, 0.01).reshape((-1, 1))\n",
    "plt.plot(x, model.predict(pol_exp.fit_transform(x)))\n",
    "plt.show()\n",
    "\n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# test_score = model.score( ? )\n",
    "\n",
    "print(f'The R2 score of the model on the test set is: {test_score:.3f}')\n",
    "\n",
    "assert test_score > 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything is correct your score is very close to 1. Which means that we have built a model that can fit this data (almost) perfectly.\n",
    "\n",
    "### 4.3. Add noise to the equation\n",
    "\n",
    "Sadly all the data that we measure or gather doesn't have the mathematical precision of the data we used here. Quite often our measurements contain noise.\n",
    "\n",
    "So let us repeat this process for data with more noise. Similarly as above, you have to choose the optimal degree of the polynomials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a helper function to create the sine train set that can also add noise to the data\n",
    "def noisy_sine_train_data(noise=None):\n",
    "    x_train = np.linspace(0, 6, 10).reshape((-1, 1))\n",
    "    y_train = np.sin(x_train)\n",
    "    \n",
    "    # If fixed, set the random seed so that the next call of the\n",
    "    # random function always returns the same result\n",
    "    if noise == 'fixed':\n",
    "        np.random.seed(1)\n",
    "    \n",
    "    x_train += np.random.randn(len(x_train)).reshape((-1, 1)) / 5\n",
    "    \n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "108fff88dfd8a0836eef11ae471ef905",
     "grade": false,
     "grade_id": "asdqet",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train = noisy_sine_train_data(noise='fixed')\n",
    "\n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# pol_exp = sklearn.preprocessing.PolynomialFeatures(degree= ? )\n",
    "\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(pol_exp.fit_transform(x_train), y_train)\n",
    "\n",
    "train_score = model.score(pol_exp.fit_transform(x_train), y_train)\n",
    "print(f'The R2 score of this method on the train set is {train_score:.3f}')\n",
    "\n",
    "assert train_score > 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what this results to in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = sine_test_data()\n",
    "print(f'The R2 score of the model on the test set is: {model.score(pol_exp.fit_transform(x_test), y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can clearly see, this result is not that good. Why do you think this is?\n",
    "\n",
    "Now plot the result to see the function you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "plt.scatter(x_train, y_train)\n",
    "x = np.arange(0,6, 0.01).reshape((-1, 1))\n",
    "plt.plot(x, model.predict(pol_exp.fit_transform(x)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this what you expect?\n",
    "\n",
    "Now repeat the process below a couple of times for random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = noisy_sine_train_data()\n",
    "\n",
    "pol_exp = sklearn.preprocessing.PolynomialFeatures(degree=9)\n",
    "\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(pol_exp.fit_transform(x_train), y_train)\n",
    "print(f'The R2 score of this method on the train set is {model.score(pol_exp.fit_transform(x_train), y_train):.3f}')\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.scatter(x_train, y_train)\n",
    "x = np.arange(x_train[0], x_train[-1], 0.01).reshape((-1, 1))\n",
    "plt.plot(x, model.predict(pol_exp.fit_transform(x)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did you observe? And what is the method learning? And how can you avoid this?\n",
    "\n",
    "Try to figure out a solution for this problem without changing the noise level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d782bc089fb01b862e98fc01d4e51cad",
     "grade": false,
     "grade_id": "qwe",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train = noisy_sine_train_data(noise='fixed')\n",
    "x_test, y_test = sine_test_data()\n",
    "\n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# pol_exp = ?\n",
    "# model = ?\n",
    "# model.fit( ? )\n",
    "\n",
    "print(f'The score of this method on the train set is: {model.score(pol_exp.fit_transform(x_train), y_train):.3f}')\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.scatter(x_train, y_train, label='train')\n",
    "plt.scatter(x_test, y_test, color='r', label='test')\n",
    "x = np.arange(0,6, 0.01).reshape((-1, 1))\n",
    "plt.plot(x, model.predict(pol_exp.fit_transform(x)))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "test_score = model.score(pol_exp.fit_transform(x_test), y_test)\n",
    "print(f'The score of the model on the test set is: {test_score:.3f}')\n",
    "\n",
    "assert test_score > 0.99, 'Adjust the degree parameter until test_score > 0.99'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Over-fitting and Cross-Validation\n",
    "\n",
    "What you have experienced above is called over-fitting and happens when your model learns the noise that is inherent in the data.\n",
    "\n",
    "This problem was caused because there were to many parameters in the model. So the model was too advanced so that it became capable of learning the noise in the data by heart. Reducing the number of parameters solves this problem. But how do you know how many parameters is optimal?\n",
    "\n",
    "(Another way to solve this problem is to use more data. Because if there are more data points in the data and if there is more noise, your model isn't able to learn all that noise anymore and you get a better result. Since it's often not possible to gather more data we will not take this approach.)\n",
    "\n",
    "In the exercise above you had to set the number of polynomial functions to get a better result, but how can you estimate this in a reliable way without manually selection the optimal parameters?\n",
    "\n",
    "### 5.1. Validation set\n",
    "\n",
    "A common way to solve this problem is through the use of a validation set. This means that you use a subset of the training data to train your model on, and another subset of the training data to validate your parameters. Based on the score of your model on this validation set you can select the optimal parameter.\n",
    "\n",
    "So use this approach to select the best number of polynomials for the noisy sine function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the data in case you skipped the previous exercise\n",
    "\n",
    "# a helper function to create the sine train set that can also add noise to the data\n",
    "def noisy_sine_train_data(noise=None):\n",
    "    x_train = np.linspace(0, 6, 10).reshape((-1, 1))\n",
    "    y_train = np.sin(x_train)\n",
    "    \n",
    "    # If fixed, set the random seed so that the next call of the\n",
    "    # random function always returns the same result\n",
    "    if noise == 'fixed':\n",
    "        np.random.seed(1)\n",
    "    \n",
    "    x_train += np.random.randn(len(x_train)).reshape((-1, 1)) / 5\n",
    "    \n",
    "    return x_train, y_train\n",
    "\n",
    "def sine_test_data():\n",
    "    x_test = 0.5 + np.arange(6).reshape((-1, 1))\n",
    "    y_test = np.sin(x_test)\n",
    "    return x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a0dc19a1878966ec9d2e18b3a6ddb6ff",
     "grade": false,
     "grade_id": "qw",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train = noisy_sine_train_data(noise='fixed')\n",
    "\n",
    "# we randomly pick 3 data points to get a nice validation set\n",
    "train_i = [0, 1, 3, 4, 6, 7, 9]\n",
    "val_i = [2, 5, 8]\n",
    "\n",
    "# create the train and validation sets\n",
    "x_train_i = x_train[train_i, :]\n",
    "y_train_i = y_train[train_i]\n",
    "x_val_i = x_train[val_i, :]\n",
    "y_val_i = y_train[val_i]\n",
    "\n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# pol_exp = sklearn.preprocessing.PolynomialFeatures(degree= ? )\n",
    "\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(pol_exp.fit_transform(x_train_i), y_train_i)\n",
    "\n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# train_score = model.score( ? )\n",
    "# validation_score = model.score( ? )\n",
    "\n",
    "print(f'The R2 score of this model on the train set is: {train_score:.3f}')\n",
    "print(f'The R2 score of this model on the validation set is: {validation_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train on the entire train set (including the validation set) and test this result on the test set with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pol_exp.degree < 5, 'Select a polynomial degree < 5'\n",
    "\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(pol_exp.fit_transform(x_train), y_train)\n",
    "\n",
    "x_test, y_test = sine_test_data()\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.scatter(x_train, y_train, label='train')\n",
    "plt.scatter(x_test, y_test, color='r', label='test')\n",
    "plt.legend()\n",
    "x = np.arange(0,6, 0.01).reshape((-1, 1))\n",
    "plt.plot(x, model.predict(pol_exp.fit_transform(x)))\n",
    "plt.show()\n",
    "\n",
    "print(f'The score of the model on the test set is: {model.score(pol_exp.fit_transform(x_test), y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this approach works to select the optimal degree. Usually the test score is lower than the validation score, but in this case it is not because the test data doesn't contain noise.\n",
    "\n",
    "### 5.2. Cross-Validation\n",
    "\n",
    "To improve this procedure you can repeat the process above for different train and validation sets so that the optimal parameter is less dependent on the way the data was selected.\n",
    "\n",
    "One basic strategy for this is **leave-one-out** cross validation, where each data point is left out of the train set once, and the model is then validated on this point. Now let's implement this. First make a 2-dimensional array `results` to store all your results using the [`np.ones()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ones.html) function: 1 dimension (row) for each validation set and 1 dimension (column) for each degree of the `PolynomialFeatures()` function. Then you loop over all the validation sets followed by a loop over all the degrees of the `PolynomialFeatures()` function you want to try out. Then set the result for that experiment in the right element of the `results` array.\n",
    "\n",
    "We will use the [mean squared error (MSE)](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) instead of R2 because that is more stable. Since the MSE measures the error, smaller values are better.\n",
    "\n",
    "Once you have your results, average them over all validation sets (using the [`np.mean()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html) function over the correct axis) so that you know the average error for each degree over all validation sets. Now find the degree with the smallest error using the [`np.argmin()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.argmin.html) function.\n",
    "\n",
    "Tip: Python doesnt have `{` and `}` for the beginning and end of for loops. It uses the tab indentation. So make sure your indentation is set right for each of the for loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02c56aebda5a4ae539e9c1657ca5389e",
     "grade": false,
     "grade_id": "q",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train = noisy_sine_train_data(noise='fixed')\n",
    "\n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# results = np.inf * np.ones(( ? , ?))\n",
    "# The results array should have a shape of \"the number of data points\" x \"the number of polynomial degrees to try\"\n",
    "# The ones are multiplied with a very large number, np.inf, since we are looking for the smallest error\n",
    "\n",
    "# for i in range( ? ):\n",
    "    train_i = np.where(np.arange(10) != i)[0]\n",
    "    x_train_i = x_train[train_i, :]\n",
    "    y_train_i = y_train[train_i]\n",
    "    x_val_i = x_train[i:i+1, :]\n",
    "    y_val_i = y_train[i:i+1]\n",
    "\n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "    # for degree in range(?):\n",
    "        # pol_exp = sklearn.preprocessing.PolynomialFeatures(degree= ? )\n",
    "\n",
    "        model = sklearn.linear_model.LinearRegression()\n",
    "        model.fit(pol_exp.fit_transform(x_train_i), y_train_i)\n",
    "        \n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "        # Fill out the results for each validation set and each degree in the results matrix\n",
    "        # results[ ? ] = sklearn.metrics.mean_squared_error(model.predict(pol_exp.fit_transform(x_val_i)), y_val_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot these results in a box plot to get an idea on how well the models performed on average.\n",
    "\n",
    "Tip: change the `max_degree` variable if you want to see more details for the lower degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_degree = 10\n",
    "\n",
    "plt.boxplot(results[:, : max_degree])\n",
    "plt.xticks(range(1, max_degree + 1), range(max_degree))\n",
    "\n",
    "plt.xlabel('Polynomial degree')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will compute the best degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f7417df8d4f4da0479e5399ad27350d",
     "grade": false,
     "grade_id": "optimal-solution-cv",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# average the results over all validation sets\n",
    "# average_results = np.mean(results, axis= ? )\n",
    "# find the optimal degree\n",
    "# degree = np.argmin( ? )\n",
    "\n",
    "print(f'The optimal degree for the polynomials is: {degree}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the model on the entire train set (including the validation set) and have a look at the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert degree == 3\n",
    "\n",
    "pol_exp = sklearn.preprocessing.PolynomialFeatures(degree=degree)\n",
    "\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(pol_exp.fit_transform(x_train), y_train)\n",
    "print(f'The score of this method on the train set is: {model.score(pol_exp.fit_transform(x_train), y_train):.3f}')\n",
    "\n",
    "plt.figure(figsize=(13, 6))\n",
    "plt.scatter(x_train, y_train, label='train')\n",
    "plt.scatter(x_test, y_test, color='r', label='test')\n",
    "plt.legend()\n",
    "x = np.arange(0,6, 0.01).reshape((-1, 1))\n",
    "plt.plot(x, model.predict(pol_exp.fit_transform(x)))\n",
    "plt.show()\n",
    "\n",
    "print(f'The score of the model on the test set is: {model.score(pol_exp.fit_transform(x_test), y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this automatic way of selecting the optimal degree has resulted in a good fit for the sine function.\n",
    "\n",
    "### 5.3 Regularisation\n",
    "\n",
    "When you have too many parameters in your model, there is a risk of over-fitting, i.e. your model learns the noise. To avoid this, techniques have been developed to make an estimation of this noise. \n",
    "\n",
    "One of these techniques is Ridge Regression. This linear regression technique has an additional parameter called the regularisation parameter. This parameter basically sets the standard deviation of the noise you want to remove. The effect in practice is that it makes sure the weights of linear regression remain small and thus less over-fitting.\n",
    "\n",
    "Since this is an additional parameter that needs to be set, it needs to be set using cross-validation as well. Luckily sklearn developed a method that does this for us in a computational efficient way called [`sklearn.linear_model.RidgeCV()`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9a7da74fa39fee9d63a93da0fe6b584b",
     "grade": false,
     "grade_id": "asdfasdf",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "x_train, y_train = noisy_sine_train_data(noise='fixed')\n",
    "\n",
    "pol_exp = sklearn.preprocessing.PolynomialFeatures(degree=9)\n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# model = sklearn.linear_model. ?\n",
    "\n",
    "\n",
    "model.fit(pol_exp.fit_transform(x_train), y_train)\n",
    "print(f'The R2 score of this method on the train set is: {model.score(pol_exp.fit_transform(x_train), y_train):.3f}')\n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.scatter(x_train, y_train, label='train')\n",
    "plt.scatter(x_test, y_test, color='r', label='test')\n",
    "plt.legend()\n",
    "x = np.arange(0,6, 0.01).reshape((-1, 1))\n",
    "plt.plot(x, model.predict(pol_exp.fit_transform(x)))\n",
    "plt.show()\n",
    "\n",
    "print(f'The R2 score of the model on the test set is: {model.score(pol_exp.fit_transform(x_test), y_test):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the result of Ridge Regression is not as good as reducing the number of features in this example. However it works a lot better than without regularisation (try that). In the example above you will notice that it makes the result a lot smoother and removes the unwanted spikes. It will actually make sure that if you have too many features you still get a reasonable result. So this means that it should be in your standard toolkit.\n",
    "\n",
    "The removal of the extra features can be automated using feature selection. A very short introduction to sklearn on the topic can be found [here](http://scikit-learn.org/stable/modules/feature_selection.html).\n",
    "\n",
    "Another method that is often used is [`sklearn.linear_model.LassoCV()`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV) which actually combines removal of features and estimation of the noise. It is however very dependent on the dataset which of the two methods performs best.\n",
    "\n",
    "Cross-validation should be applied to any parameter you set in your function and that without looking at the test set.\n",
    "\n",
    "Over-fitting is one of the biggest issues in machine learning and a lot of the research that is currently being done in machine learning is a search for techniques to avoid over-fitting. As a starting point we list a few of the techniques that you can use to avoid over-fitting:\n",
    "* Use more data\n",
    "* Artificially generate more data based on the original data\n",
    "* Use a smaller model (with less parameters)\n",
    "* Use less features (and thus less parameters)\n",
    "* Use a regularisation parameter\n",
    "* Artificially add noise to your model\n",
    "* Only use linear models or make sure that the non-linearity in your model is closer to a linear function\n",
    "* Combine multiple models that each over-fit in their own way into what is called an ensemble\n",
    "\n",
    "### 5.4 Extrapolation\n",
    "\n",
    "Now let's extend the range of the optimal plot you achieved from -4 to 10. What do you see? Does it look like a sine function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = noisy_sine_train_data(noise='fixed')\n",
    "\n",
    "pol_exp = sklearn.preprocessing.PolynomialFeatures(degree=3)\n",
    "\n",
    "model = sklearn.linear_model.RidgeCV()\n",
    "model.fit(pol_exp.fit_transform(x_train), y_train)\n",
    "print('The R2 score of this method on the train set is:',\n",
    "      f'{model.score(pol_exp.fit_transform(x_train), y_train):.3f}')\n",
    "\n",
    "# Now test outside the area of the training\n",
    "x_test_extended = np.array([-3,-2,-1,7,8,9]).reshape((-1, 1))\n",
    "y_test_extended = np.sin(x_test_extended)\n",
    "\n",
    "plt.figure(figsize=(13, 8))\n",
    "plt.scatter(x_train, y_train, label='train')\n",
    "plt.scatter(x_test_extended, y_test_extended, color='r', label='test')\n",
    "plt.legend()\n",
    "x = np.arange(-4,10, 0.01).reshape((-1, 1))\n",
    "plt.plot(x, model.predict(pol_exp.fit_transform(x)))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print('The R2 score of the model on the test set outside the area used for training is:',\n",
    "      f'{model.score(pol_exp.fit_transform(x_test_extended), y_test_extended):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the extrapolation results for non-linear regression are even worse than for those of linear regression. This is because models only work well in the input space they have been trained in. \n",
    "\n",
    "A possible way to be able to extrapolate and to use a non-linear method is to use forecasting techniques. This is handled in part 7, an optional part for those interested and going through the tutorial quite fast. Otherwise continue to the section on classification in exercise 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classification\n",
    "\n",
    "In classification the purpose is to separate 2 classes. As an example we will use the double spiral. It is a very common toy example in machine learning and allows you to visually show what is going on.\n",
    "\n",
    "As shown in the graph below the purpose is to separate the blue from the red dots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some code to generate spirals. You can ignore this for now.\n",
    "\n",
    "# To comply with standards in machine learning we use x1 and x2 as opposed to x and y for this graph \n",
    "# because y is reserved for the output in Machine Learning (= 0 or 1 in this case)\n",
    "\n",
    "r = np.arange(0.1, 1.5, 0.0001)\n",
    "theta = 2 * np.pi * r\n",
    "x1_0 = r * np.cos(theta)\n",
    "x2_0 = r * np.sin(theta)\n",
    "x1_1 = - r * np.cos(theta)\n",
    "x2_1 = - r * np.sin(theta)\n",
    "\n",
    "perm_indices = np.random.permutation(range(len(x1_0)))\n",
    "x1_0_rand = x1_0[perm_indices[ : 1000]] + np.random.randn(1000) / 5\n",
    "x2_0_rand = x2_0[perm_indices[ : 1000]] + np.random.randn(1000) / 5\n",
    "x1_1_rand = x1_1[perm_indices[1000 : 2000]] + np.random.randn(1000) / 5\n",
    "x2_1_rand = x2_1[perm_indices[1000 : 2000]] + np.random.randn(1000) / 5\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(x1_0_rand, x2_0_rand, color = 'b', alpha=0.6, linewidth=0)\n",
    "plt.scatter(x1_1_rand, x2_1_rand, color = 'r', alpha=0.6, linewidth=0)\n",
    "\n",
    "plt.plot(x1_0, x2_0, color = 'b', lw=3)\n",
    "plt.plot(x1_1, x2_1, color='r', lw=3)\n",
    "plt.xlim(-2, 2)\n",
    "plt.ylim(-2, 2)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a colored image this is easy to do, but when you remove the color it becomes much harder. Can you do the classification in the image below?\n",
    "\n",
    "In black the samples from the train set are shown and in yellow the samples from the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train and validation set\n",
    "\n",
    "x_train_0 = np.concatenate((x1_0_rand[ : 800].reshape((-1,1)), x2_0_rand[ : 800].reshape((-1,1))), axis=1)\n",
    "y_train_0 = np.zeros((len(x_train_0),))\n",
    "x_train_1 = np.concatenate((x1_1_rand[ : 800].reshape((-1,1)), x2_1_rand[ : 800].reshape((-1,1))), axis=1)\n",
    "y_train_1 = np.ones((len(x_train_1),))\n",
    "\n",
    "x_val_0 = np.concatenate((x1_0_rand[800 : ].reshape((-1,1)), x2_0_rand[800 : ].reshape((-1,1))), axis=1)\n",
    "y_val_0 = np.zeros((len(x_val_0),))\n",
    "x_val_1 = np.concatenate((x1_1_rand[800 : ].reshape((-1,1)), x2_1_rand[800 : ].reshape((-1,1))), axis=1)\n",
    "y_val_1 = np.ones((len(x_val_1),))\n",
    "\n",
    "x_train = np.concatenate((x_train_0, x_train_1), axis=0)\n",
    "y_train = np.concatenate((y_train_0, y_train_1), axis=0)\n",
    "\n",
    "x_val = np.concatenate((x_val_0, x_val_1), axis=0)\n",
    "y_val = np.concatenate((y_val_0, y_val_1), axis=0)\n",
    "\n",
    "# Plot the train and test data\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(x_train[:, 0], x_train[:, 1], color='k', alpha=0.6, linewidth=0)\n",
    "plt.scatter(x_val[:, 0], x_val[:, 1], color='y', alpha=0.6, linewidth=0)\n",
    "plt.xlim(-2, 2)\n",
    "plt.ylim(-2, 2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see classifying is very hard to do when you don't get the answer even if you saw the solution earlier. But you will see that machine learning algorithms can solve this quite well if they can learn from examples.\n",
    "\n",
    "This figure also illustrates that the train and validation set are from the same distribution, which is why they look very similar on the plot. If you want to put a model trained on this data set in production and the real data is from the same distribution, you can expect similar results in real life as on your validation set.\n",
    "\n",
    "### 6.1 Linear classifier\n",
    "\n",
    "Let's try to do this with a linear classifier.\n",
    "\n",
    "Logistic regression, despite its name, is a linear model for classification rather than regression. Its sklearn implementation is [`sklearn.linear_model.LogisticRegression()`](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "719de52ed0ea836a7a2eb11fd27393a0",
     "grade": false,
     "grade_id": "asdfasd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# model = sklearn.linear_model. ?\n",
    "# model.fit( ? )\n",
    "\n",
    "train_score = sklearn.metrics.accuracy_score(model.predict(x_train), y_train)\n",
    "print(f'The train accuracy is: {train_score:.3f}')\n",
    "val_score = sklearn.metrics.accuracy_score(model.predict(x_val), y_val)\n",
    "print(f'The validation accuracy is: {val_score:.3f}')\n",
    "\n",
    "assert val_score > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick and dirty helper function to plot the decision boundaries\n",
    "def plot_decision_boundary(model, pol_exp=None):\n",
    "    n=250\n",
    "    lin_space = np.linspace(-2, 2, num=n).reshape((-1, 1))\n",
    "    x1 = np.dot(lin_space, np.ones((1, n))).reshape((-1, 1))\n",
    "    x2 = np.dot(np.ones((n, 1)), lin_space.T).reshape((-1, 1))\n",
    "    \n",
    "    x = np.concatenate((x1, x2), axis=1)\n",
    "    if pol_exp is None:\n",
    "        y = model.predict(x)\n",
    "    else:\n",
    "        y = model.predict(pol_exp.fit_transform(x))    \n",
    "    i_0 = np.where(y < 0.5)\n",
    "    i_1 = np.where(y > 0.5)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.scatter(x[i_0, 0], x[i_0, 1], color='b', s=2, alpha=0.5, linewidth=0, marker='s')\n",
    "    plt.scatter(x[i_1, 0], x[i_1, 1], color='r',s=2, alpha=0.5, linewidth=0, marker='s')\n",
    "    plt.plot(x1_0, x2_0, color = 'b', lw=3)\n",
    "    plt.plot(x1_1, x2_1, color='r', lw=3)\n",
    "    plt.xlim(-2, 2)\n",
    "    plt.ylim(-2, 2)\n",
    "    \n",
    "# Call the function\n",
    "plot_decision_boundary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see a linear classifier returns a linear decision boundary.\n",
    "\n",
    "### 6.2 Non-linear classification\n",
    "\n",
    "Now let's do this better with a non-linear classifier using polynomials. Play with the degree of the polynomial expansion and look for the effect on the validation set accuracy of the [`LogisticRegressionCV()`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html) model. This is a more advanced version of the default [`LogisticRegression()`](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression) that uses cross validation to tune its hyper-parameters. What gives you the best results?\n",
    "\n",
    "_If you get a lot of \"failed to converge\" warnings consider increasing the `max_iter` parameter to 1000 or so. Getting some warnings is normal._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54703f46ca790c7fe04f94d54f8c0179",
     "grade": false,
     "grade_id": "asdfas",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# model = sklearn.linear_model. ?\n",
    "# pol_exp = sklearn.preprocessing.PolynomialFeatures(degree= ? )\n",
    "# model.fit( ? )\n",
    "\n",
    "train_score = sklearn.metrics.accuracy_score(model.predict(pol_exp.fit_transform(x_train)), y_train)\n",
    "print(f'The train accuracy is: {train_score:.3f}')\n",
    "val_score = sklearn.metrics.accuracy_score(model.predict(pol_exp.fit_transform(x_val)), y_val)\n",
    "print(f'The validation accuracy is: {val_score:.3f}')\n",
    "\n",
    "plot_decision_boundary(model, pol_exp=pol_exp)\n",
    "\n",
    "assert val_score >= 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything went well you should get a validation/test accuracy very close to 0.8.\n",
    "\n",
    "### 6.3 Random Forests\n",
    "\n",
    "An often used technique in machine learning are random forests. Basically they are [decision trees](https://en.wikipedia.org/wiki/Decision_tree_learning), or in programmers terms, if-then-else structures, like the one shown below.\n",
    "\n",
    "<img src=\"images/tree.png\" width=70%>\n",
    "\n",
    "Decision trees are know to over-fit a lot because they just learn the train set by heart and store it. Random forests on the other hand combine multiple different (randomly initialized) decision trees that all over-fit in their own way. But by combining their output using a voting mechanism, they tend to cancel out each other's mistakes. This approach is called an [ensemble](https://en.wikipedia.org/wiki/Ensemble_learning) and can be used for any combination of machine learning techniques. A schema representation of how such a random forest works is shown below.\n",
    "\n",
    "<img src=\"images/random_forest.jpg\">\n",
    "\n",
    "Now let's try to use a random forest to solve the double spiral problem. (see [`sklearn.ensemble.RandomForestClassifier()`](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "816d1a617a4380e8a88cfd3c9d853294",
     "grade": false,
     "grade_id": "asdfa",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "\n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# model = ?\n",
    "# model.fit( ? )\n",
    "\n",
    "train_score = sklearn.metrics.accuracy_score(model.predict(x_train), y_train)\n",
    "print(f'The train accuracy is: {train_score:.3f}')\n",
    "val_score = sklearn.metrics.accuracy_score(model.predict(x_val), y_val)\n",
    "print(f'The validation accuracy is: {val_score:.3f}')\n",
    "\n",
    "plot_decision_boundary(model)\n",
    "\n",
    "assert val_score > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see they are quite powerful right out of the box without any parameter tuning. But we can get the results even better with some fine tuning.\n",
    "\n",
    "Try changing the `min_samples_leaf` parameter for values between 0 and 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8b29b6867ff2d516dd718c356a58fda",
     "grade": false,
     "grade_id": "asdf",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# model = sklearn.ensemble.RandomForestClassifier(min_samples_leaf= ? )\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "train_score = sklearn.metrics.accuracy_score(model.predict(x_train), y_train)\n",
    "print(f'The train accuracy is: {train_score:.3f}')\n",
    "val_score = sklearn.metrics.accuracy_score(model.predict(x_val), y_val)\n",
    "print(f'The validation accuracy is: {val_score:.3f}')\n",
    "\n",
    "plot_decision_boundary(model)\n",
    "\n",
    "assert val_score > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `min_samples_leaf` parameter sets the number of data points that can create a new branch/leaf in the tree. So in practice it limits the depth of the decision tree. The bigger this parameter is, the less deep the tree will be and less likely each tree will over-fit.\n",
    "\n",
    "For this parameter you can set integer numbers to set the specific number of samples, or you can use values between 0 and 0.5 to express a percentage of the size of the dataset. Since you might experiment with a smaller dataset to roughly tune your parameters, it is best to use values between 0 and 0.5 so that the value you chose is not as dependant on the size of the dataset you are working with.\n",
    "\n",
    "Now that you have found the optimal `min_samples_leaf` run the code again with the same parameter. Do you get the same result? Why not?\n",
    "\n",
    "Another parameter to play with is the `n_estimators` parameter. Play with only this parameter to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f58861bad508fc36f8921ad3876f478",
     "grade": false,
     "grade_id": "asd",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# model = sklearn.ensemble.RandomForestClassifier(n_estimators= ? )\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "train_score = sklearn.metrics.accuracy_score(model.predict(x_train), y_train)\n",
    "print(f'The train accuracy is: {train_score:.3f}')\n",
    "val_score = sklearn.metrics.accuracy_score(model.predict(x_val), y_val)\n",
    "print(f'The validation accuracy is: {val_score:.3f}')\n",
    "\n",
    "plot_decision_boundary(model)\n",
    "\n",
    "assert val_score > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see increasing the number of estimators improves the model and reduces over-fitting. This parameter actually sets the number of trees in the random forest. The more trees there are in the forest the better the result is. But obviously it requires more computing power so that is the limiting factor here.\n",
    "\n",
    "This is the basic idea behind ensembles: if you combine more tools you get a good result on average.\n",
    "\n",
    "Now try combining the `n_estimators` and `min_samples_leaf` parameter below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdab44f96434d8e74c1e9adda21c8382",
     "grade": false,
     "grade_id": "as",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# model = sklearn.ensemble.RandomForestClassifier(n_estimators= ? , min_samples_leaf= ? )\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "train_score = sklearn.metrics.accuracy_score(model.predict(x_train), y_train)\n",
    "print(f'The train accuracy is: {train_score:.3f}')\n",
    "val_score = sklearn.metrics.accuracy_score(model.predict(x_val), y_val)\n",
    "print(f'The validation accuracy is: {val_score:.3f}')\n",
    "\n",
    "plot_decision_boundary(model)\n",
    "\n",
    "assert val_score > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As you have noticed by now it seems that random forests are less powerful than linear regression with polynomial feature extraction. This is because these polynomials are ideally suited for this task. This also means that you could get a better result if you would also apply polynomial expansion for random forests. Try that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dabda2076fed6efec7df60956e69c10b",
     "grade": false,
     "grade_id": "a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# model = sklearn.ensemble.RandomForestClassifier(n_estimators= ? , min_samples_leaf= ? )\n",
    "# pol_exp = sklearn.preprocessing.PolynomialFeatures(degree= ?)\n",
    "# model.fit( ? )\n",
    "\n",
    "train_score = sklearn.metrics.accuracy_score(model.predict(pol_exp.fit_transform(x_train)), y_train)\n",
    "print(f'The train accuracy is: {train_score:.3f}')\n",
    "val_score = sklearn.metrics.accuracy_score(model.predict(pol_exp.fit_transform(x_val)), y_val)\n",
    "print(f'The validation accuracy is: {val_score:.3f}')\n",
    "\n",
    "plot_decision_boundary(model, pol_exp=pol_exp)\n",
    "\n",
    "assert val_score > 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you have may have noticed, it is hard to get results that are better than the ones obtained using logistic regression. This illustrates that linear techniques are very powerful and often underrated. But in some situations they are not powerful enough and you need something stronger like a random forest or even neural networks (check [this](https://playground.tensorflow.org/#dataset=spiral&noise=45) simulator if you want to play with the latter).\n",
    "\n",
    "There is one neat trick that can be used for random forests. If you set the `n_jobs` it will use more than 1 core to compute. Set it to -1 to use all the cores (including hyper-threading cores). But don't do that during this tutorial because that would block the machine you are all working on.\n",
    "\n",
    "To avoid over-fitting, you can set the `max_depth` parameter for random forests which limits the maximum depth of each tree. Alternatively, you can set the `min_samples_split` parameter which determines how many data points you need at least before you create another split (this is an additional if-else structure) while building the tree. Or the `min_samples_leaf` that sets the minimum amount of data points you have in each leaf. All 3 parameters are dependent on the number of data points in your dataset especially the last 2 so don't forget to adapt them if you have been playing around with a small subset of the data. (A good trick to solve this might be to use a range similar to `[0.0001, 0.001, 0.01, 0.1] * len(x_train)`. Feel free to extend the range in any direction. It is generally good practice to construct them using a log scale like in the example, or better like this: `10.0**np.arange(-5, 0, 0.5) * len(x_train)`.) In our experience `min_samples_split` or `min_samples_leaf` give slightly better results and it usually doesn't make sense to combine more than 1 of these parameters.\n",
    "\n",
    "In the previous exercises we have done a lot of the optimizations on the test set. This should of course be avoided. What you should do instead is to optimize and select your model using a validation set and of course you should automate this process as shown in one of the earlier exercises. One thing to take into account here is that you should use multiple initialisation of a random forest because the decision trees is randomly generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Forecasting (Optional)\n",
    "\n",
    "We are going to forecast page views data, very similar to the data used in the anomaly detection section. The data contains 1 sample per hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train_set_forecasting.pickle', 'rb') as file:\n",
    "    train_set = pickle.load(file, encoding='latin1')\n",
    "\n",
    "print(f'Shape of the train set = {train_set.shape}')\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(train_set)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the graph above you can clearly see that there is a rising trend in the data.\n",
    "\n",
    "### 7.1 One-step ahead prediction\n",
    "\n",
    "This forecasting section will describe the one-step ahead prediction. In this case, this means that we will only predict the next data point i.e. the number of page views in the next hour.\n",
    "\n",
    "Now let's first build a model that tries to predict the next data point from the previous one. \n",
    "\n",
    "We will use a technique called teacher forcing where we assume that the output of the previous prediction is correct. This means that we can use the original time series as input. Now we only need to align input and output so that the output corresponds to the next sample in the input time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.linear_model\n",
    "import sklearn.gaussian_process\n",
    "\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "\n",
    "# the input x_train contains all the data except the last data point\n",
    "x_train = train_set[ : -1].reshape((-1, 1)) # the reshape is necessary since sklearn requires a 2 dimensional array\n",
    "\n",
    "# the output y_train contains all the data except the first data point\n",
    "y_train = train_set[1 : ]\n",
    "\n",
    "# this code fits the model on the train data\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# this score gives you how well it fits on the train set\n",
    "# higher is better and 1.0 is perfect\n",
    "print(f'The R2 train score of the linear model is {model.score(x_train, y_train):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the score above, the model is not perfect but it seems to get a relatively high score. Now let's make a prediction into the future and plot this.\n",
    "\n",
    "To predict the data point after that we will use the predicted data to make a new prediction. The code below shows how this works for this data set using the linear model you used earlier. Don't forget to fill out the missing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b75d67ba8bb3a239b23cf020a017f221",
     "grade": false,
     "grade_id": "nof_predictions",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "n_predictions = 100\n",
    "\n",
    "import copy\n",
    "# use the last data point as the first input for the predictions\n",
    "x_test = copy.deepcopy(train_set[-1]) # make a copy to avoid overwriting the training data\n",
    "\n",
    "prediction = []\n",
    "for i in range(n_predictions):\n",
    "    # predict the next data point\n",
    "    y_test = model.predict([[x_test]])[0] # sklearn requires a 2 dimensional array and returns a one-dimensional one\n",
    "    \n",
    "    ##### Implement this part of the code #####\n",
    "    raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "    # prediction.append( ? )\n",
    "    # x_test = ?\n",
    "\n",
    "prediction = np.array(prediction)\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(np.concatenate((train_set, prediction)), 'g')\n",
    "plt.plot(train_set, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the image above the model doesn't quite seem to fit the data well. Let's see how we can improve this.\n",
    "\n",
    "### 7.2 Multiple features\n",
    "\n",
    "If your model is not smart enough there is a simple trick in machine learning to make your model more intelligent (but also more complex). This is by adding more features.\n",
    "\n",
    "To make our model better we will use more than 1 sample from the past. To make your life easier there is a simple function below that will create a data set for you. The ```width``` parameter sets the number of hours in the past that will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time_series_to_train_data(ts, width):\n",
    "    x_train, y_train = [], []\n",
    "    for i in range(len(ts) - width - 1):\n",
    "        x_train.append(ts[i : i + width])\n",
    "        y_train.append(ts[i + width])\n",
    "    return np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 5\n",
    "x_train, y_train = convert_time_series_to_train_data(train_set, width)\n",
    "\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the print above both `x_train` and `y_train` contains 303 data points. For `x_train` you see that there are now 5 features which contain the page views from the 5 past hours.\n",
    "\n",
    "So let's have a look what the increase from 1 to 5 features results to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 5\n",
    "x_train, y_train = convert_time_series_to_train_data(train_set, width)\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "print(f'The R2 score of the linear model with width={width} is {model.score(x_train, y_train):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now change the ```width``` parameter to see if you can get a better score.\n",
    "\n",
    "### 7.3 Over-fitting\n",
    "\n",
    "\n",
    "Now execute the code below to see the prediction of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# this is a helper function to make the predictions\n",
    "def predict(model, train_set, width, n_points):\n",
    "    prediction = []\n",
    "    # create the input data set for the first predicted output\n",
    "    # copy the data to make sure the original is not overwritten\n",
    "    x_test = copy.deepcopy(train_set[-width : ]) \n",
    "    for i in range(n_points):\n",
    "        # predict only the next data point\n",
    "        prediction.append(model.predict(x_test.reshape((1, -1))))\n",
    "        # use the newly predicted data point as input for the next prediction\n",
    "        x_test[0 : -1] = x_test[1 : ]\n",
    "        x_test[-1] = prediction[-1]\n",
    "    return np.array(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_predictions = 200\n",
    "prediction = predict(model, train_set, width, n_predictions)\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(np.concatenate((train_set, prediction[:,0])), 'g')\n",
    "plt.plot(train_set, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the image above the prediction is not what you would expect from a perfect model. What happened is that the model learned the training data by heart without 'understanding' what the data is really about. This phenomenon is called over-fitting and will always occur if you make your model too complex.\n",
    "\n",
    "Now play with the width variable below to see if you can find a more sensible width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8feb79fbf075823932c57521919ac55",
     "grade": false,
     "grade_id": "jkl",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# width = ?\n",
    "\n",
    "x_train, y_train = convert_time_series_to_train_data(train_set, width)\n",
    "model = sklearn.linear_model.LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "print(f'The R2 score of the linear model with width={width} is {model.score(x_train, y_train):.3f}')\n",
    "\n",
    "prediction = predict(model, train_set, width, 200)\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(np.concatenate((train_set, prediction[:,0])), 'g')\n",
    "plt.plot(train_set, 'b')\n",
    "plt.show()\n",
    "\n",
    "assert width > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you will have noticed by now is that it is better to have a non-perfect score which will give you a much better outcome. Now try the same thing for the following models:\n",
    "* ```sklearn.linear_model.RidgeCV()```\n",
    "* ```sklearn.linear_model.LassoCV()```\n",
    "* ```sklearn.ensemble.RandomForestRegressor()```\n",
    "\n",
    "The first 2 models also estimate the noise that is present in the data to avoid over-fitting. `RidgeCV()` will keep the weights that are found small, but it won't put them to zero. `LassoCV()` on the other hand will put several weights to 0. Execute ```model.coef_``` to see the actual coefficients that have been found.\n",
    "\n",
    "`RandomForestRegressor()` is the regression variant of the `RandomForestClassifier()` and is therefore thus a non-linear method. This makes this method a lot more complex and therefore it will be able to represent more complex shapes than the linear method. This also means that it is much more capable to learn the data by heart (and thus to over-fit). In many cases however this additional complexity allows to better understand the data given the correct parameter settings (try a couple of times `width=25` (since it is random) and see what the results are; set the `n_estimators` parameter to a higher number to get a more stable results). \n",
    "\n",
    "### 7.4 Automation\n",
    "\n",
    "What we have done up to now is manually selecting the best outcome based on the test result. This can be considered cheating because you have just created a self-fulfilling prophecy. Additionally it is not only cheating it is also hard to find the exact `width` that gives the best result by just visually inspecting it. So we need a more objective approach to solve this.\n",
    "\n",
    "To automate this process you can use a validation set. In this case we will use the last 48 hours of the training set to validate the score and select the best parameter value. This means that we will have to use a subset of the training set to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "878a9a1b67102633fe609f2ecc2891b7",
     "grade": false,
     "grade_id": "find_best_model",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "model_generators = [sklearn.linear_model.LinearRegression(), \n",
    "                    sklearn.linear_model.RidgeCV(cv=3),\n",
    "                    sklearn.linear_model.LassoCV(cv=3), \n",
    "                    sklearn.ensemble.RandomForestRegressor(n_estimators=10)]\n",
    "best_score = 0\n",
    "\n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# for model_gen in ? :\n",
    "#    for width in range( ? , ? ): \n",
    "        x_train, y_train = convert_time_series_to_train_data(train_set, width)\n",
    "        # train the model on the first 48 hours\n",
    "        x_train_i, y_train_i = x_train[ : -48, :], y_train[ : -48]\n",
    "        # use the last 48 hours for validation\n",
    "        x_val_i, y_val_i = x_train[-48 : ], y_train[-48 : ]\n",
    "        \n",
    "        # there is a try except clause here because some models do not converge for some data\n",
    "        try:\n",
    "            # Constructs a new, untrained, model with the same parameters\n",
    "            model = sklearn.base.clone(model_gen, safe=True)\n",
    "            ##### Implement this part of the code #####\n",
    "            raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "            # model.fit( ? , ? )\n",
    "            # this_score = ?\n",
    "            \n",
    "            if this_score > best_score:\n",
    "                best_score = this_score\n",
    "                # Constructs a new, untrained, model with the same parameters\n",
    "                best_model = sklearn.base.clone(model, safe=True)\n",
    "                best_width = width\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print(f'{best_model.__class__.__name__} was selected as the best model with a width of {best_width}',\n",
    "      f'and a validation R2 score of {best_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything is correct the LassoCV methods was selected.\n",
    "\n",
    "Now we are going to train this best model on all the data. In this way we use all the available data to build a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b18aa7ae6392940841e9b8821f77a4a",
     "grade": false,
     "grade_id": "best_model_gen_plot",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# width = ?\n",
    "# model = ?\n",
    "\n",
    "x_train, y_train = convert_time_series_to_train_data(train_set, width)\n",
    "\n",
    "##### Implement this part of the code #####\n",
    "raise NotImplementedError(\"Code not implemented, follow the instructions.\")\n",
    "# model.fit( ? , ? )\n",
    "\n",
    "n_predictions = 200\n",
    "prediction = predict(model, train_set, width, n_predictions)\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.plot(np.concatenate((train_set, prediction[:,0])), 'g')\n",
    "plt.plot(train_set, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the optimal result found here might not be the best visually, it is a far better result than the one you selected manually just because there was no cheating involved ;-).\n",
    "\n",
    "Some additional info:\n",
    "* This noise level of `RidgeCV()` and `LassoCV()` is estimated by automatically performing train and validation within the method itself. This will make them much more robust against over-fitting. The actual method used is [Cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)) which is a better approach of what we do here because it repeats the training and validation multiple times for different training and validation sets. The parameter that is set for these methods is often called the regularization parameter in literature and is well suited to avoid over-fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 8. Main take home messages\n",
    "\n",
    "Because we can't cover everything, we listed all the basics of what you should take home before working on your own machine learning project below. \n",
    "\n",
    "### 8.1 The basic rules of machine learning\n",
    "\n",
    "Any good club has its own set of rules. The rules for machine learning club are the following:\n",
    "\n",
    "* First rule of ML is: Over-fitting is a real problem and try anything to avoid it\n",
    "* Second rule of ML is: You are probably over-fitting. Are you sure you are not fitting on your test data?\n",
    "* Third rule of ML is: You think over-fitting will not happen to you, but it is happening right now!\n",
    "* Fourth rule of ML is: Talk about it with your peers because over-fitting is a real issue.\n",
    "\n",
    "### 8.2 Our winning strategy\n",
    "\n",
    "Although we'd like to claim it as ours, it is a general (non-written) consensus amongst data scientists to use the following approach. Even experts should not skip any of the steps below.\n",
    "\n",
    "1. Create a train set and a test set\n",
    "2. Rescale your train set to zero-mean-unit-variance (most methods assume gaussian distributed data)\n",
    "3. Don't look at the test set\n",
    "4. Implement a cross-validation framework\n",
    "5. Try **linear regression with regularisation** for regression (`RidgeCV` or `LassoCV`) and classification (`LogisticRegressionCV`).\n",
    "6. Try techniques to avoid over-fitting\n",
    "7. Check the validation score\n",
    "8. If the results are not optimal and there is no over-fitting going on try **adding features** else go to step 17\n",
    "9. Rescale your features to zero-mean-unit-variance (most methods assume gaussian distributed data) or select those features that have this property\n",
    "10. Try techniques to avoid over-fitting (including removing features for more info see [feature selection techniques](http://scikit-learn.org/stable/modules/feature_selection.html))\n",
    "11. Check the validation score\n",
    "12. If the results are not optimal and there is no over-fitting going on try **random forests** else go to step 17\n",
    "13. Try techniques to avoid over-fitting (such as feature selection, to rank the features you can use [this approach](http://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html))\n",
    "14. Check the validation score\n",
    "15. If the results are not optimal and there is no over-fitting going on try **neural networks** or **deep learning** else go to step 17. You will only gain from using \n",
    "16. Try techniques to avoid over-fitting\n",
    "17. Only in the end check the score on the test set and make sure it is similar to the validation score. Otherwise you have been over-fitting and you need to take a couple steps back.\n",
    "18. Make an ensemble of your best (but significantly different) methods\n",
    "19. Finally build the model using all the data available and run it in production\n",
    "\n",
    "You can try other machine learning techniques, but usually the difference is quite small. So don't waste too much time on getting to know them because they all have their own quirks and specific ways of over-fitting. Besides maybe most important of all, Kaggle competitions are usually won with one of these techniques.\n",
    "\n",
    "If you do want to dive into other methods or if you want more details on the methods discussed here, the [sklearn website](http://scikit-learn.org/stable/) is a good starting point.\n",
    "\n",
    "### 8.3 How to avoid over-fitting\n",
    "\n",
    "As you should know by now over-fitting is one of the biggest issues in machine learning. So pay attention for it. \n",
    "\n",
    "Below you can find some of the most common techniques to avoid over-fitting:\n",
    "\n",
    "* Use more data\n",
    "* Artificially generate more data based on the original data\n",
    "* Use a smaller model (with fewer parameters)\n",
    "* Use fewer features (and thus fewer parameters)\n",
    "* Use a regularisation parameter\n",
    "* Artificially add noise to your model (can be random noise or can be on/of noise in neural networks so that you get dropout)\n",
    "* Only use linear models (or in neural networks make sure that the non-linearity in your model is closer to a linear function)\n",
    "* Combine multiple models that each over-fit in their own peculiar way into what is called an ensemble\n",
    "\n",
    "\n",
    "### 8.4 Most common features\n",
    "\n",
    "Although there is no general rule to which features you should use, there are a couple of features that come back regularly:\n",
    "\n",
    "* Log: Take the log of the data to make it more Gaussian. This works best for data that is exponentially or log-normally distributed\n",
    "* Polynomials: The square is quite common but higher orders are often used as well\n",
    "* Differentials: The first and sometimes the second derivative are used (see [`numpy.diff()`](https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.diff.html))\n",
    "* Integrals (use [`numpy.sum()`](https://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.sum.html) for example to implement it)\n",
    "* Mean: Often used to smooth the data\n",
    "* Median: Same as the mean but this ignores outliers\n",
    "* Standard deviation or variance\n",
    "* Skewness and kurtosis: These are rarely used but sometimes they contain valuable information\n",
    "* Fourier transform: If your data contains a frequency spectrum. Typically used when processing speech and sound. (see [`numpy.fft.fft()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.fft.fft.html#numpy.fft.fft))\n",
    "* Frequency filtering: Similar to the fourier transform (see [`scipy.signal.butter()`](https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.signal.butter.html#scipy.signal.butter))\n",
    "* Spatial filters: Are often used for images. Edge detectors for example\n",
    "* Any other feature that seems to make sense regarding your data\n",
    "\n",
    "\n",
    "## Feedback\n",
    "\n",
    "If you have any feedback regarding this tutorial, feel free to share it with us. You can mail to <a href=\"mailto:pieter.buteneers@gmail.com\">pieter.buteneers@gmail.com</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
